{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PAawc8c8ckW7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "metadata": {
        "id": "9pm6D3RWdqcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567d9a77-6465-486d-d7e5-6207d180260f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing on a cat image"
      ],
      "metadata": {
        "id": "_oodzxkahCtk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/cat.jpg\"\n",
        "img = image.load_img(img_path,target_size=(224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "of0oZVfmezgm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block prepares an image for input into the ResNet50 model:\n",
        "\n",
        "img_path = \"/content/cat.jpg\": This line sets the file path to the image you want to process. In this case, it's a file named cat.jpg located in the /content/ directory.\n",
        "img = image.load_img(img_path,target_size=(224,224)): This line loads the image from the specified img_path and resizes it to 224x224 pixels. This is the required input size for the ResNet50 model.\n",
        "x = image.img_to_array(img): This converts the loaded image (which is in PIL format) into a NumPy array. This is necessary because neural networks work with numerical data.\n",
        "x = np.expand_dims(x,axis=0): This adds an extra dimension to the array. The ResNet50 model expects a batch of images as input, even if you're only providing one. This line reshapes the array from (height, width, channels) to (1, height, width, channels).\n",
        "x = preprocess_input(x): This performs any necessary preprocessing on the image data, such as scaling or centering the pixel values, according to the requirements of the ResNet50 model trained on ImageNet.\n",
        "In essence, these steps take an image file, load it, resize it, convert it to a numerical format, and prepare it in the correct shape and format for the ResNet50 model to make predictions."
      ],
      "metadata": {
        "id": "ukfLkMMkhQP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print(\"Predicted : \" , decode_predictions(preds,top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka_oR78dfkFj",
        "outputId": "cb9b1b2f-6850-4efe-dacd-cf6dde43331e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Predicted :  [('n02123597', 'Siamese_cat', np.float32(0.96504766)), ('n02124075', 'Egyptian_cat', np.float32(0.005839006)), ('n02497673', 'Madagascar_cat', np.float32(0.0019207763))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block uses the pre-trained ResNet50 model to make a prediction on the processed image data and then decodes the prediction to show the top 3 predicted classes:\n",
        "\n",
        "preds = model.predict(x): This line uses the loaded and preprocessed image data (x) as input to the model (the ResNet50 model). The predict() method outputs the model's predictions for each class.\n",
        "print(\"Predicted : \" , decode_predictions(preds,top=3)[0]): This line first decodes the predictions (preds) into human-readable class labels. decode_predictions is a function from Keras that maps the output probabilities to ImageNet class names. top=3 specifies that you want the top 3 predicted classes. [0] is used to access the predictions for the first (and in this case, only) image in the batch. Finally, it prints the predicted classes and their confidence scores."
      ],
      "metadata": {
        "id": "lgDEkE2OhWyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now testing on an chair image"
      ],
      "metadata": {
        "id": "E-sAsIsOga9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/chair.jpeg\"\n",
        "img = image.load_img(img_path,target_size=(224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "oNCnkR8hgamt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print(\"Predicted : \" , decode_predictions(preds,top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odT9p1uMgRZU",
        "outputId": "ea9efa4c-d421-43e1-8297-ad686f311375"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n",
            "Predicted :  [('n04344873', 'studio_couch', np.float32(0.3733532)), ('n03201208', 'dining_table', np.float32(0.17629433)), ('n03899768', 'patio', np.float32(0.08802598))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now testing on dog image"
      ],
      "metadata": {
        "id": "wlZDChswgzqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/dog.jpg\"\n",
        "img = image.load_img(img_path,target_size=(224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "WLJUZGVCg7eP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x)\n",
        "print(\"Predicted : \" , decode_predictions(preds,top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udzzg-9Ogoyx",
        "outputId": "0c1d011c-fb7f-419d-c35c-eb3e96979699"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "Predicted :  [('n02104029', 'kuvasz', np.float32(0.51913244)), ('n02099601', 'golden_retriever', np.float32(0.19797565)), ('n02111500', 'Great_Pyrenees', np.float32(0.18791029))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "drHMhVhmgxko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}